{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess the simulated 4dstem\n",
    "\n",
    "Chia-Hao Lee\n",
    "\n",
    "cl2696@cornell.edu\n",
    "\n",
    "Created 2025.02.18"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "\n",
    "import h5py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.ndimage import gaussian_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working dir:  H:\\workspace\\ptyrad\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "work_dir = \"H:\\workspace\\ptyrad\"\n",
    "os.chdir(work_dir)\n",
    "print(\"Current working dir: \", os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def meas_add_poisson_noise(meas, unit, value, scan_step_size):\n",
    "    ''' Add Poisson noise to meas '''\n",
    "    # meas (N, ky, kx)\n",
    "    # value, scalar float\n",
    "    # scan_step_size, scalar float, unit: Ang\n",
    "    \n",
    "    if unit == 'total_e_per_pattern':\n",
    "        total_electron = value\n",
    "        dose = total_electron / scan_step_size **2\n",
    "    elif unit == 'e_per_Ang2':\n",
    "        dose = value\n",
    "        total_electron =  dose * scan_step_size **2 # Number of electron per diffraction pattern\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported unit: '{unit}' for Poisson noise. Expected 'total_e_per_pattern' or 'e_per_Ang2'.\")\n",
    "    \n",
    "    print(f\"total electron per measurement = dose x scan_step_size^2 = {dose:.3f}(e-/Ang^2) x {scan_step_size:.3f}(Ang)^2 = {total_electron:.3f}\")\n",
    "    meas = meas / meas.sum((-2,-1))[:,None,None] # Make each slice of the meas to sum to 1\n",
    "    meas = np.random.poisson(meas * total_electron)\n",
    "    print(f\"Adding Poisson noise with a total electron per diffraction pattern of {int(total_electron)}\")\n",
    "    \n",
    "    return meas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine the hdf5 into a single one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdf5_dir = 'data\\paper\\simu_tBL_WSe2/'\n",
    "\n",
    "hdf5s = []\n",
    "for file in os.listdir(hdf5_dir):\n",
    "    if file.startswith('phonon_temporal_N16384_dp128_start_'):\n",
    "        hdf5s.append(file)\n",
    "hdf5s.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve cbeds\n",
    "cbeds_resample = np.zeros([16384,128,128], dtype=np.float32)\n",
    "for i,file in enumerate(hdf5s):\n",
    "    with h5py.File(os.path.join(hdf5_dir, file), 'a') as hf:\n",
    "        dp = hf['/dp'][:]\n",
    "        cbeds_resample[i*1024:(i+1)*1024,:,:] = dp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve metadata\n",
    "with h5py.File(os.path.join(hdf5_dir, file), 'a') as hf:\n",
    "    potential_resample = hf['/full_volume'][()]\n",
    "    potential_crop = hf['/volume'][()]\n",
    "    gt_phase = hf['/gt_phase'][()]\n",
    "    abtem_params = {}\n",
    "    for key, value in hf['abtem_params'].items():\n",
    "        abtem_params[key] = hf['abtem_params'][key][()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding source size (partial spatial coherence) of Gaussian blur std = 0.7925 scan_step sizes or 0.3400 Ang to measurements along the scan directions\n",
      "Reshape measurements back to (N, ky, kx) = (16384, 128, 128)\n"
     ]
    }
   ],
   "source": [
    "# Apply partial spatial coherence\n",
    "N_scan_slow, N_scan_fast = 128, 128\n",
    "source_size_std_ang = 0.34 # Ang\n",
    "scan_step_size = 0.429 # Ang\n",
    "\n",
    "cbeds_resample = cbeds_resample.reshape(N_scan_slow, N_scan_fast, cbeds_resample.shape[-2], cbeds_resample.shape[-1])\n",
    "source_size_std_px = source_size_std_ang / scan_step_size # The source size blur std is now in unit of scan steps\n",
    "cbeds_resample = gaussian_filter(cbeds_resample, sigma=source_size_std_px, axes=(0,1)) # Partial spatial coherence is approximated by mixing DPs at nearby probe positions\n",
    "print(f\"Adding source size (partial spatial coherence) of Gaussian blur std = {source_size_std_px:.4f} scan_step sizes or {source_size_std_ang:.4f} Ang to measurements along the scan directions\")\n",
    "cbeds_resample = cbeds_resample.reshape(-1, cbeds_resample.shape[-2], cbeds_resample.shape[-1])\n",
    "print(f\"Reshape measurements back to (N, ky, kx) = {cbeds_resample.shape}\")\n",
    "abtem_params['use_partial_spatial_source'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved hdf5 as data\\paper\\simu_tBL_WSe2/phonon_temporal_spatial_N16384_dp128.hdf5\n"
     ]
    }
   ],
   "source": [
    "output_path = os.path.join(hdf5_dir, 'phonon_temporal_spatial_N16384_dp128.hdf5')\n",
    "with h5py.File(output_path, 'a') as hf:\n",
    "    hf.create_dataset('/full_volume',   data = potential_resample)\n",
    "    hf.create_dataset('/volume',        data = potential_crop)\n",
    "    hf.create_dataset('/gt_phase',      data = gt_phase)\n",
    "    hf.create_dataset('/dp',            data = cbeds_resample)\n",
    "    param_group = hf.create_group('abtem_params')\n",
    "    for key,value in abtem_params.items():\n",
    "        param_group.create_dataset(key, data=value)\n",
    "print(f\"Saved hdf5 as {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add noise for a single file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing with dose = 10000.0\n",
      "total electron per measurement = dose x scan_step_size^2 = 10000.000(e-/Ang^2) x 0.429(Ang)^2 = 1840.410\n",
      "Adding Poisson noise with a total electron per diffraction pattern of 1840\n",
      "Normalizing measurements by 4.4510498 so the averaged measurement has max intensity at 1 for ease of display/comparison\n",
      "Preprocessing with dose = 100000.0\n",
      "total electron per measurement = dose x scan_step_size^2 = 100000.000(e-/Ang^2) x 0.429(Ang)^2 = 18404.100\n",
      "Adding Poisson noise with a total electron per diffraction pattern of 18404\n",
      "Normalizing measurements by 44.168945 so the averaged measurement has max intensity at 1 for ease of display/comparison\n",
      "Preprocessing with dose = 1000000.0\n",
      "total electron per measurement = dose x scan_step_size^2 = 1000000.000(e-/Ang^2) x 0.429(Ang)^2 = 184041.000\n",
      "Adding Poisson noise with a total electron per diffraction pattern of 184040\n",
      "Normalizing measurements by 440.85614 so the averaged measurement has max intensity at 1 for ease of display/comparison\n",
      "Preprocessing with dose = 10000000.0\n",
      "total electron per measurement = dose x scan_step_size^2 = 10000000.000(e-/Ang^2) x 0.429(Ang)^2 = 1840410.000\n",
      "Adding Poisson noise with a total electron per diffraction pattern of 1840409\n",
      "Normalizing measurements by 4407.4362 so the averaged measurement has max intensity at 1 for ease of display/comparison\n"
     ]
    }
   ],
   "source": [
    "output_path = 'data\\paper\\simu_tBL_WSe2/phonon_temporal_spatial_N16384_dp128.hdf5'\n",
    "scan_step_size = 0.429 # Ang\n",
    "\n",
    "# Open the HDF5 file in append mode to read and write\n",
    "with h5py.File(output_path, 'a') as hf:\n",
    "    # Load the '/dp' dataset\n",
    "    dp = hf['/dp'][:]\n",
    "    \n",
    "    for dose in [1e4, 1e5, 1e6, 1e7]:\n",
    "        print(f\"Preprocessing with dose = {dose}\")\n",
    "        dp_noise = meas_add_poisson_noise(dp, unit='e_per_Ang2', value=dose, scan_step_size=scan_step_size)\n",
    "        \n",
    "        # Normalizing the meas_data so that the averaged DP has max at 1. This will make each DP has max somewhere ~ 1\n",
    "        normalization_const = (np.mean(dp_noise, 0).max())\n",
    "        dp_noise = dp_noise / normalization_const \n",
    "        dp_noise = dp_noise.astype('float32')\n",
    "        print(f\"Normalizing measurements by {normalization_const:.8g} so the averaged measurement has max intensity at 1 for ease of display/comparison\")\n",
    "    \n",
    "        # Save the processed data back to the same HDF5 as new datasets\n",
    "        # Check if the dataset already exists, then delete it to overwrite\n",
    "        if f'/dp_{dose:.0e}' in hf:\n",
    "            del hf[f'/dp_{dose:.0e}']\n",
    "        hf.create_dataset(f'/dp_{dose:.0e}', data=dp_noise)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cornell",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
